{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from lib.read_data import dataset,Datasets\n",
    "from math import copysign\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# feature extractors\n",
    "from sklearn.decomposition import PCA\n",
    "# classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "# from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "# finetuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_set(data_table,test_size=0.25,normalization=True):\n",
    "    '''\n",
    "    convert a pandas dataframe data table into Datasets(dataset,dataset)\n",
    "    '''\n",
    "    train, test = train_test_split(data_table,test_size=0.25)\n",
    "    train_x = train[[col for col in train.columns\n",
    "                     if col not in ['zscore','direction','cpgName']]]\n",
    "    features = train_x.columns\n",
    "    if normalization:\n",
    "        minMaxScaler = preprocessing.MinMaxScaler()\n",
    "        train_x = minMaxScaler.fit_transform(train_x)\n",
    "        test_x = minMaxScaler.fit_transform(test[[col for col in \n",
    "                                                  train.columns\n",
    "                      if col not in ['zscore','direction','cpgName']]])\n",
    "    else:\n",
    "        train_x = np.array(train_x)\n",
    "        test_x = np.array(test[[col for col in train.columns\n",
    "                      if col not in ['zscore','direction','cpgName']]])\n",
    "    train_y = np.array(train['direction'],dtype=np.int8)\n",
    "    test_y = np.array(test['direction'],dtype=np.int8)\n",
    "\n",
    "    return Datasets(train=dataset(train_x,train_y),\n",
    "                    test=dataset(test_x,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonder dataset loaded. (2131, 8)\n",
      "Westra with all features dataset loaded. (2131, 8)\n",
      "Westra with bonder features dataset loaded. (2131, 8)\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "\n",
    "    def load_bonderWestraData(path):\n",
    "        data = pd.read_csv(bonder_path,sep=',')\n",
    "        # print(data.head())\n",
    "        def binarize(row):\n",
    "            if row > 0:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        data['direction'] = data['zscore'].apply(binarize)\n",
    "        dataset = read_data_set(data)\n",
    "        return dataset\n",
    "\n",
    "\n",
    "    bonder_path = 'data/bonder_withzscore.csv'\n",
    "    westra_allFeat_path = 'data/westra_all_with_zscore.csv.csv'\n",
    "    westra_bonderFeat_path = 'data/westra_bonderfeat_with_zscore.csv'\n",
    "\n",
    "    bonder = load_bonderWestraData(bonder_path)\n",
    "    westra_allFeat = load_bonderWestraData(westra_allFeat_path)\n",
    "    westra_bonderFeat = load_bonderWestraData(westra_bonderFeat_path)\n",
    "\n",
    "    print('Bonder dataset loaded.',bonder.train.values.shape)\n",
    "    print('Westra with all features dataset loaded.',bonder.train.values.shape)\n",
    "    print('Westra with bonder features dataset loaded.',\n",
    "           bonder.train.values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.52657515e-01, 0.00000000e+00, 1.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 9.52252117e-04],\n",
       "       [1.88313974e-01, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "        1.00000000e+00, 1.00000000e+00, 3.28335049e-05],\n",
       "       [2.18233017e-01, 4.64285714e-01, 0.00000000e+00, ...,\n",
       "        8.57142857e-01, 3.21428571e-01, 1.08897791e-03],\n",
       "       ...,\n",
       "       [4.31186202e-01, 7.14285714e-02, 0.00000000e+00, ...,\n",
       "        7.14285714e-02, 0.00000000e+00, 1.31583490e-03],\n",
       "       [4.25202394e-01, 3.57142857e-02, 0.00000000e+00, ...,\n",
       "        7.14285714e-02, 0.00000000e+00, 1.90579182e-03],\n",
       "       [3.30165435e-01, 4.64285714e-01, 0.00000000e+00, ...,\n",
       "        8.92857143e-01, 0.00000000e+00, 1.77770092e-02]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bonder.train.values[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
