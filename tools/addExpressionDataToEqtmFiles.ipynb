{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from eqtmZscore to withExpressionData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bonder-eQTMsFDR0.0-CpGLevel-split.txt', '2017-12-09-eQTLsFDR-et0.0-flipped.txtsplit.txt', '2017-12-09-eQTLsFDR-et0.0-flipped.txt', 'westra-eQTMsFDR0.0-CpGLevel-split.txt', '2017-12-09-eQTLsFDR-gt0.0-flipped.txtsplit.txt', 'zScoresBonderFinalUnique.csv', 'bonder-eQTMsFDR0.0-CpGLevel-split-uniqueCGs.txt', 'zScoresWestraFinalUnique.csv', 'westra-eQTMsFDR0.0-CpGLevel-split-uniqueCGs.txt', '2017-12-09-eQTLsFDR-gt0.0-flipped.txt']\n",
      "['fdr_gt0.2_sm0.3.txt', 'random20000-eQTLsFDR-gt0.05-flipped.txt', 'random20k_gt0.5.txt', 'random20k_gt0.05_sm0.1.txt', 'random20k_gt0.1_sm0.2.txt', 'random20k_gt0.3_sm0.4.txt', 'random20k_gt0.2_sm0.3.txt', '2017-12-09-eQTLsFDR-gt0.05-flipped.txt', 'fdr_gt0.5.txt', 'random20k_gt0.4_sm0.5.txt', 'fdr_gt0.4_sm0.5.txt', 'random20k_gt0.5_withZscore.txt', 'random20k_gt0.5_withTss.txt', 'fdr_gt0.3_sm0.4.txt', 'fdr_gt0.1_sm0.2.txt', 'selectAccordingFDR.sh', 'fdr_gt0.05_sm0.1.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_FOLDER = '/home/shuang/projects/boxy_eqtm/data'\n",
    "EQTM_DATADIR = os.path.join(DATA_FOLDER,'eqtmZscores')\n",
    "INPUT_FOLDER_1 = os.path.join(EQTM_DATADIR,'fdr_sm0.05')\n",
    "filenames1 = ['2017-12-09-eQTLsFDR-et0.0-flipped.txt','2017-12-09-eQTLsFDR-gt0.0-flipped.txt']\n",
    "INPUT_FOLDER_2 = os.path.join(EQTM_DATADIR,'fdr_gt0.05')\n",
    "filenames2 = ['random20k_gt0.5_withTss.txt']\n",
    "OUTPUT_FOLDER = os.path.join(EQTM_DATADIR,'withExpressionData')\n",
    "print(os.listdir(INPUT_FOLDER_1))\n",
    "print(os.listdir(INPUT_FOLDER_2))\n",
    "\n",
    "# expression data\n",
    "expression_filepath = os.path.join(DATA_FOLDER,'features','meanVar','expression-MeanAndVarianceRows.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19960, 4) \n",
      "                 ID     N      Mean           Var\n",
      "0  ENSG00000180008  2905 -3.547676  48060.577013\n",
      "1  ENSG00000167693  2905  6.642518  47299.021217\n",
      "2  ENSG00000064703  2905  5.160337  48509.749511\n",
      "3  ENSG00000189292  2905 -2.695654  48425.761353\n",
      "4  ENSG00000243772  2905 -2.186263  48663.139410\n"
     ]
    }
   ],
   "source": [
    "# read expression data\n",
    "expression_data = pd.read_csv(expression_filepath,sep='\\t')\n",
    "print(expression_data.shape,'\\n',expression_data.head())\n",
    "expression_dict = expression_data[['ID','Mean','Var']].set_index('ID').T.to_dict('list')\n",
    "# print(expression_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-09-eQTLsFDR-et0.0-flipped.txt\n",
      "Saved to : /home/shuang/projects/boxy_eqtm/data/eqtmZscores/withExpressionData/2017-12-09-eQTLsFDR-et0_withExpression.txt\n",
      "2017-12-09-eQTLsFDR-gt0.0-flipped.txt\n",
      "Saved to : /home/shuang/projects/boxy_eqtm/data/eqtmZscores/withExpressionData/2017-12-09-eQTLsFDR-gt0_withExpression.txt\n",
      "random20k_gt0.5_withTss.txt\n",
      "random20k_gt0.5_withTss\n",
      "Saved to : /home/shuang/projects/boxy_eqtm/data/eqtmZscores/withExpressionData/random20k_gt0.5_withTss_withExpression.txt\n"
     ]
    }
   ],
   "source": [
    "# do the same thing for files in filenames1 and filenames2\n",
    "for filename in filenames1:\n",
    "    print(filename)\n",
    "    eqtm_name = '.'.join(filename.split('.')[:-2])\n",
    "    input_filepath = os.path.join(INPUT_FOLDER_1,filename)\n",
    "    eqtm = pd.read_csv(input_filepath,sep='\\t',index_col=0)\n",
    "    eqtm['expressionMean'] = [expression_dict[key][0] for key in eqtm['ProbeName'].values]\n",
    "    eqtm['expressionVar'] = [expression_dict[key][1] for key in eqtm['ProbeName'].values]\n",
    "    eqtm_savepath = os.path.join(OUTPUT_FOLDER,eqtm_name+'_withExpression.txt')\n",
    "    eqtm.to_csv(eqtm_savepath)\n",
    "    print('Saved to :',eqtm_savepath)\n",
    "\n",
    "for filename in filenames2:\n",
    "    print(filename)\n",
    "    eqtm_name = '.'.join(filename.split('.')[:-1])\n",
    "    print(eqtm_name)\n",
    "    input_filepath = os.path.join(INPUT_FOLDER_2,filename)\n",
    "    eqtm = pd.read_csv(input_filepath,sep=',',index_col=0)\n",
    "    eqtm['expressionMean'] = [expression_dict[key][0] for key in eqtm['ProbeName'].values]\n",
    "    eqtm['expressionVar'] = [expression_dict[key][1] for key in eqtm['ProbeName'].values]\n",
    "    eqtm_savepath = os.path.join(OUTPUT_FOLDER,eqtm_name+'_withExpression.txt')\n",
    "    eqtm.to_csv(eqtm_savepath)\n",
    "    print('Saved to :',eqtm_savepath)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from withExpressionData to withExpressionTSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "withExpressionDir = os.path.join(EQTM_DATADIR,'withExpressionData')\n",
    "withExpressionTSSDir = os.path.join(EQTM_DATADIR,'withExpressionTSS')\n",
    "tss_path = '/home/shuang/projects/boxy_eqtm/data/features/TSSDistance/Homo_sapiens.GRCh37.71.gtf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tss(tss_path):\n",
    "    # read tss file from tss_path\n",
    "    colnames = ['chr','regionFunction','regionType','startSite',\n",
    "                'endSite','score','strand','sthunknown','geneInfo']\n",
    "    dtype = {'chr':object,'regionFunction':object,'regionType':object,\n",
    "             'startSite':int,'endSite':int,'score':object,\n",
    "             'strand':object,'sthunknown':object,'geneInfo':object}\n",
    "    tss_raw = pd.read_csv(tss_path,sep='\\t',header=None,names=colnames,dtype=dtype)\n",
    "    return tss_raw\n",
    "\n",
    "def addTssDistance2eQTMwithZscoreFile(eQTM_path,tss_raw,save_path = None):\n",
    "    '''\n",
    "    add TssDistance to eqtmZscore file\n",
    "    INPUT:\n",
    "        eQTM_path, string, path to eqtmZscore file\n",
    "        tss_path, string, path to TssSite file\n",
    "        save_path, string, path to save the new eqtmZscore_withTSSDistance file\n",
    "    OUTPUT:\n",
    "        eQTMs, pandas dataframe\n",
    "    '''\n",
    "    \n",
    "\n",
    "    # reading the eQTMs\n",
    "    eQTMs = pd.read_csv(eQTM_path,sep=',')\n",
    "\n",
    "    # extract gene name from geneInfo for tss file\n",
    "    def findGeneName(item):\n",
    "        item = [thing for thing in list(filter(None,item.strip().split(\";\")))][0]\n",
    "        name = item.replace('\"','').replace(';','').strip().split(' ')[1]\n",
    "        return name\n",
    "    tss_raw['geneName'] = tss_raw['geneInfo'].apply(findGeneName)\n",
    "\n",
    "    # find the tss sites for each gene in the tss file\n",
    "    groupbyTss = tss_raw.groupby('geneName').agg({\n",
    "        'chr':lambda x: x.unique(),\n",
    "        'startSite':np.min,\n",
    "        'endSite':np.max,\n",
    "        'strand':lambda x: x.unique()\n",
    "    })\n",
    "    def findTssSite(series):\n",
    "        if series[3] == '-':\n",
    "            return series[2]\n",
    "        else:\n",
    "            return series[1]\n",
    "    groupbyTss['TssSite'] = groupbyTss.apply(findTssSite,axis=1)\n",
    "\n",
    "    # add tss sites and tss distance to the eqtm file\n",
    "    def mapSite(row):\n",
    "        return groupbyTss.loc[row]['TssSite']\n",
    "    def calculateDis(row):\n",
    "        return abs(row[0]-row[1])\n",
    "    def findChr(row):\n",
    "        return groupbyTss.loc[row]['chr']\n",
    "    def checkChr(row):\n",
    "        if str(row[0])==str(row[1]):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    eQTMs['TssSite'] = eQTMs['ProbeName'].apply(mapSite)\n",
    "    eQTMs['chr'] = eQTMs['ProbeName'].apply(findChr)\n",
    "    eQTMs['TssDistance'] = eQTMs[['SNPChrPos','TssSite']].apply(calculateDis,axis=1)\n",
    "    eQTMs['checkChr'] = eQTMs[['chr','SNPChr']].apply(checkChr,axis=1)\n",
    "    # check whether they are from the same chromosome\n",
    "    assert len(eQTMs['checkChr'].unique()) == 1\n",
    "\n",
    "    if save_path:\n",
    "        # save the eQTM file\n",
    "        eQTMs.to_csv(save_path,index=False)\n",
    "        print('Saved eQTM file to: ',save_path)\n",
    "\n",
    "    return eQTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSS file loaded.\n",
      "Saved eQTM file to:  /home/shuang/projects/boxy_eqtm/data/eqtmZscores/withExpressionTSS/2017-12-09-eQTLsFDR-gt0_withExpressionTss.txt\n",
      "Saved eQTM file to:  /home/shuang/projects/boxy_eqtm/data/eqtmZscores/withExpressionTSS/random20k_gt0.5_withTss_withExpressionTss.txt\n",
      "Saved eQTM file to:  /home/shuang/projects/boxy_eqtm/data/eqtmZscores/withExpressionTSS/2017-12-09-eQTLsFDR-et0_withExpressionTss.txt\n"
     ]
    }
   ],
   "source": [
    "tss_raw = read_tss(tss_path)\n",
    "print('TSS file loaded.')\n",
    "for filename in os.listdir(withExpressionDir):\n",
    "    eqtm_name = '.'.join(filename.split('.')[:-1])\n",
    "    eQTM_path = os.path.join(withExpressionDir,filename)\n",
    "    save_path = os.path.join(withExpressionTSSDir,eqtm_name+'Tss.txt')\n",
    "    _ = addTssDistance2eQTMwithZscoreFile(eQTM_path,tss_raw,save_path = save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from withExpressionTss to withExpressionTssMethy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "withExpressionTssMethyDir = os.path.join(EQTM_DATADIR,'withExpressionTSSMethy')\n",
    "methy_filepath = '/home/shuang/projects/boxy_eqtm/data/features/meanVar/methylation-MeanAndVarianceRows.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_methy(methy_filepath):\n",
    "    methy = pd.read_csv(methy_filepath,sep='\\t')\n",
    "    methy_dict = methy[['ID','Mean','Var']].set_index('ID').T.to_dict('list')\n",
    "    return methy_dict\n",
    "def add_Methy(input_filepath,methy_dict,output_filepath):\n",
    "    inputfile = pd.read_csv(input_filepath,sep=',',index_col=0)\n",
    "    inputfile['SNPName_ProbeName'] = ['{}_{}'.format(row[0],row[1]) \n",
    "                                      for row in inputfile[['SNPName','ProbeName']].values]\n",
    "    inputfile['methyMean'] = [methy_dict[row][0] for row in inputfile['SNPName'].values]\n",
    "    inputfile['methyVar'] = [methy_dict[row][1] for row in inputfile['SNPName'].values]\n",
    "    inputfile.to_csv(output_filepath)\n",
    "    print('Saved file to:',output_filepath)\n",
    "    return inputfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Methylation file loaded.\n",
      "Saved file to: /home/shuang/projects/boxy_eqtm/data/eqtmZscores/withExpressionTSSMethy/2017-12-09-eQTLsFDR-et0_withExpressionTssMethy.txt\n",
      "Saved file to: /home/shuang/projects/boxy_eqtm/data/eqtmZscores/withExpressionTSSMethy/2017-12-09-eQTLsFDR-gt0_withExpressionTssMethy.txt\n",
      "Saved file to: /home/shuang/projects/boxy_eqtm/data/eqtmZscores/withExpressionTSSMethy/random20k_gt0.5_withTss_withExpressionTssMethy.txt\n"
     ]
    }
   ],
   "source": [
    "# methy = read_methy(methy_filepath)\n",
    "print(\"Methylation file loaded.\")\n",
    "for filename in os.listdir(withExpressionTSSDir):\n",
    "    filepath = os.path.join(withExpressionTSSDir,filename)\n",
    "    eqtm_name = '.'.join(filename.split('.')[:-1])\n",
    "    save_path = os.path.join(withExpressionTssMethyDir,eqtm_name+'Methy.txt')\n",
    "    _ = add_Methy(filepath,methy,save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add overlapRatio to eqtm files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eqtm_withTSSExpressionMethy_dir = os.path.join(EQTM_DATADIR,'withExpressionTSSMethy')\n",
    "eqtm_overlapRatio_dir = os.path.join(DATA_FOLDER,'dataReadyForModeling','overlapRatioTssMeanVar')\n",
    "eqtm_overlap_withTSSExpressionMethy = os.path.join(EQTM_DATADIR,'final')\n",
    "et_overlap_name = '2017-12-09-eQTLsFDR-et0.0-flipped_overlapRatio.txt'\n",
    "et_eqtm_name = '2017-12-09-eQTLsFDR-et0_withExpressionTssMethy.txt'\n",
    "gt_overlap_name = '2017-12-09-eQTLsFDR-gt0.0-flipped_overlapRatio.txt'\n",
    "gt_eqtm_name = '2017-12-09-eQTLsFDR-gt0_withExpressionTssMethy.txt'\n",
    "random_overlap_name = 'random20k_gt0.5_overlapRatio.txt'\n",
    "random_eqtm_name = 'random20k_gt0.5_withTss_withExpressionTssMethy.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_overlap_to_eqtm(eqtm_filename, overlap_filename):\n",
    "    overlap_filepath = os.path.join(eqtm_overlapRatio_dir,overlap_filename)\n",
    "    overlap = pd.read_csv(overlap_filepath,sep='\\t',index_col=0)\n",
    "    \n",
    "    eqtm_filepath = os.path.join(eqtm_withTSSExpressionMethy_dir,eqtm_filename)\n",
    "    eqtm = pd.read_csv(eqtm_filepath,index_col=0)\n",
    "#     print(eqtm.head())\n",
    "#     print(overlap.head())\n",
    "    overlap_dict = overlap.T.to_dict()\n",
    "    for col in overlap.columns:\n",
    "        eqtm[col] = [overlap_dict[row][col] for row in eqtm['SNPName'].values]\n",
    "    eqtm.to_csv(os.path.join(eqtm_overlap_withTSSExpressionMethy,\n",
    "                             '.'.join(eqtm_filename.split('.')[:-1])+'Overlap.txt'))\n",
    "    return eqtm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = add_overlap_to_eqtm(et_eqtm_name,et_overlap_name)\n",
    "_ = add_overlap_to_eqtm(gt_eqtm_name,gt_overlap_name)\n",
    "_ = add_overlap_to_eqtm(random_eqtm_name,random_overlap_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# concate all files together and save in final folder as multi_class.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_class_savepath = os.path.join(eqtm_overlap_withTSSExpressionMethy,'multi_class.txt')\n",
    "# eqtm_overlap_withTSSExpressionMethy\n",
    "multi_class = []\n",
    "for filename in os.listdir(eqtm_overlap_withTSSExpressionMethy)[1:]:\n",
    "    filepath = os.path.join(eqtm_overlap_withTSSExpressionMethy,filename)\n",
    "    filecontent = pd.read_csv(filepath)\n",
    "    multi_class.append(filecontent)\n",
    "multi_class_pd = pd.concat(multi_class)\n",
    "multi_class_pd.head()\n",
    "multi_class_pd.to_csv(multi_class_savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import __init__path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from lib.read.read_data import load_data\n",
    "from lib.read.dataset_class import dataset\n",
    "from lib.model.modelBuild import convModelObject\n",
    "from math import copysign\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def examineModel(model_name,trainPath,testPath,label_name='OverallZScore',savefilename=None,\n",
    "                 keep=[],exclude=[],display=True):\n",
    "    res = {'sensitivity':[],'specificity':[],'auc':[]}\n",
    "    res2 = {'sensitivity':[],'specificity':[],'auc':[]}\n",
    "    for i in range(4):\n",
    "        data = load_data(trainPath,label_name=label_name,keep=keep,exclude=exclude)\n",
    "        features_to_use = [col for col in data.train.values.columns if col not in keep]\n",
    "        train_data = dataset(data.train.values[features_to_use],data.train.labels.astype('int8'))\n",
    "        valid_data = dataset(data.test.values[features_to_use],data.test.labels.astype('int8'))\n",
    "\n",
    "        model = choose_model(model_name,len(features_to_use))\n",
    "        print(model.pipeline, model.param_grid)\n",
    "        model.savefilename = savefilename\n",
    "\n",
    "        sensitivity,specificity,auc = \\\n",
    "        model.train_and_display_output(train_data=train_data,\n",
    "                                 valid_data=valid_data,\n",
    "                                 returnRes=True,\n",
    "                                 display=display)\n",
    "        res['sensitivity'].append(sensitivity)\n",
    "        res['specificity'].append(specificity)\n",
    "        res['auc'].append(auc)\n",
    "        if trainPath != testPath:\n",
    "            test_data = load_data(testPath,keep=keep,\n",
    "                                  exclude=exclude,test_size=1).test\n",
    "            sensitivity2,specificity2,auc2 = \\\n",
    "            model.calculate_output(model.classifier,test_data)\n",
    "            print('>>> test on another dataset: sensitivity: '+\n",
    "            '{:.{prec}}\\tspecificity: {:.{prec}f}\\tauc:{}'.\\\n",
    "                  format(sensitivity2,specificity2,auc2,prec=3))\n",
    "            res2['sensitivity'].append(sensitivity2)\n",
    "            res2['specificity'].append(specificity2)\n",
    "            res2['auc'].append(auc2)\n",
    "    print('Sensitivity:',\n",
    "    np.mean(np.array(res['sensitivity'])),\n",
    "    np.std(np.array(res['sensitivity'])),\n",
    "    np.mean(np.array(res2['sensitivity'])),\n",
    "    np.std(np.array(res2['sensitivity'])))\n",
    "    print('Specificity:',\n",
    "    np.mean(np.array(res['specificity'])),\n",
    "    np.std(np.array(res['specificity'])),\n",
    "    np.mean(np.array(res2['specificity'])),\n",
    "    np.std(np.array(res2['specificity'])))\n",
    "    print('AUC:',\n",
    "    np.mean(np.array(res['auc'])),\n",
    "    np.std(np.array(res['auc'])),\n",
    "    np.mean(np.array(res2['auc'])),\n",
    "    np.std(np.array(res2['auc'])))\n",
    "\n",
    "def compare_Tss_meanVar_exclude(filepath,testpath):\n",
    "    exclude1 = ['cpgName','cpgName_split','TSS_Distance','methyMean','methyVar']\n",
    "    exclude2 = ['cpgName','cpgName_split','methyMean','methyVar']\n",
    "    exclude3 = ['cpgName','cpgName_split','TSS_Distance','methyVar']\n",
    "    exclude4 = ['cpgName','cpgName_split','TSS_Distance','methyMean']\n",
    "    exclude5 = ['cpgName','cpgName_split','methyMean']\n",
    "    exclude6 = ['cpgName','cpgName_split','methyVar']\n",
    "    exclude7 = ['cpgName','cpgName_split','TSS_Distance']\n",
    "    exclude8 = ['cpgName','cpgName_split']\n",
    "\n",
    "    # only check dataset with TSS and dataset with TSS & meanVariance\n",
    "    for exclude in [exclude2,exclude8]:\n",
    "        print('Not using features:',exclude)\n",
    "        modelPerformance(filepath,testpath,exclude=exclude)\n",
    "\n",
    "def choose_model(model_name,num_features):\n",
    "    if model_name=='ranfor':\n",
    "        pipeline = Pipeline(steps=[('pca',PCA()),('ranfor',\n",
    "                                           RandomForestClassifier())])\n",
    "        n_estimators = [10,50,100]\n",
    "        class_weight = ['balanced',{1:4,0:1},{1:2,0:1}]\n",
    "        n_components = np.arange(2,num_features,int(num_features/5))\n",
    "        param_grid = [{'pca__n_components':n_components,\n",
    "                       'ranfor__n_estimators':n_estimators,\n",
    "                       'ranfor__class_weight':class_weight}]\n",
    "    elif model_name=='knn':\n",
    "        pipeline = Pipeline(steps=[('kneighbor',\n",
    "                                    KNeighborsClassifier())])\n",
    "        # train the model!\n",
    "        n_neighbors = range(2,10,2)\n",
    "        weights = ['uniform','distance']\n",
    "        param_grid = [{'kneighbor__n_neighbors':n_neighbors,\n",
    "                       'kneighbor__weights':weights}]\n",
    "    model = convModelObject(name='model_name',\n",
    "                      pipeline=pipeline,\n",
    "                      param_grid=param_grid)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test binary classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data loaded with shape: (7497, 62)\n",
      "Data Normalized.\n",
      "Check the null values:\n",
      "Here are columns with NaN values:\n",
      "Check the loaded dataset: \n",
      " train with shape (5622, 39)\n",
      "test with shape: (1875, 39)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('ranfor', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "      ...n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))]) [{'pca__n_components': array([ 2,  9, 16, 23, 30, 37]), 'ranfor__n_estimators': [10, 50, 100], 'ranfor__class_weight': ['balanced', {1: 4, 0: 1}, {1: 2, 0: 1}]}]\n",
      "Start training...\n",
      "Model Description:\n",
      " Pipeline(memory=None,\n",
      "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=23, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('ranfor', RandomForestClassifier(bootstrap=True, class_weight={1: 2, 0: 1},\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_...mators=100, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))])\n",
      ">>> best model results: sensitivity: 0.55\tspecificity: 0.980\tauc:0.94\n",
      "Raw data loaded with shape: (7497, 62)\n",
      "Data Normalized.\n",
      "Check the null values:\n",
      "Here are columns with NaN values:\n",
      "Check the loaded dataset: \n",
      " train with shape (5622, 39)\n",
      "test with shape: (1875, 39)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('ranfor', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "      ...n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))]) [{'pca__n_components': array([ 2,  9, 16, 23, 30, 37]), 'ranfor__n_estimators': [10, 50, 100], 'ranfor__class_weight': ['balanced', {1: 4, 0: 1}, {1: 2, 0: 1}]}]\n",
      "Start training...\n",
      "Model Description:\n",
      " Pipeline(memory=None,\n",
      "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=23, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('ranfor', RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_no...mators=100, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))])\n",
      ">>> best model results: sensitivity: 0.43\tspecificity: 0.990\tauc:0.94\n",
      "Raw data loaded with shape: (7497, 62)\n",
      "Data Normalized.\n",
      "Check the null values:\n",
      "Here are columns with NaN values:\n",
      "Check the loaded dataset: \n",
      " train with shape (5622, 39)\n",
      "test with shape: (1875, 39)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('ranfor', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "      ...n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))]) [{'pca__n_components': array([ 2,  9, 16, 23, 30, 37]), 'ranfor__n_estimators': [10, 50, 100], 'ranfor__class_weight': ['balanced', {1: 4, 0: 1}, {1: 2, 0: 1}]}]\n",
      "Start training...\n",
      "Model Description:\n",
      " Pipeline(memory=None,\n",
      "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=23, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('ranfor', RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_no...mators=100, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))])\n",
      ">>> best model results: sensitivity: 0.53\tspecificity: 0.980\tauc:0.93\n",
      "Raw data loaded with shape: (7497, 62)\n",
      "Data Normalized.\n",
      "Check the null values:\n",
      "Here are columns with NaN values:\n",
      "Check the loaded dataset: \n",
      " train with shape (5622, 39)\n",
      "test with shape: (1875, 39)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('ranfor', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "      ...n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))]) [{'pca__n_components': array([ 2,  9, 16, 23, 30, 37]), 'ranfor__n_estimators': [10, 50, 100], 'ranfor__class_weight': ['balanced', {1: 4, 0: 1}, {1: 2, 0: 1}]}]\n",
      "Start training...\n",
      "Model Description:\n",
      " Pipeline(memory=None,\n",
      "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=23, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('ranfor', RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_no...mators=100, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))])\n",
      ">>> best model results: sensitivity: 0.48\tspecificity: 0.990\tauc:0.94\n",
      "Sensitivity: 0.4975 0.046569840025492915 nan nan\n",
      "Specificity: 0.9850000000000001 0.0050000000000000044 nan nan\n",
      "AUC: 0.9375 0.004330127018922149 nan nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shuang/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/shuang/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/shuang/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/numpy/core/_methods.py:135: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/home/shuang/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/numpy/core/_methods.py:105: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/home/shuang/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/numpy/core/_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data loaded with shape: (28454, 62)\n",
      "Data Normalized.\n",
      "Check the null values:\n",
      "Here are columns with NaN values:\n",
      "Check the loaded dataset: \n",
      " train with shape (21340, 39)\n",
      "test with shape: (7114, 39)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('ranfor', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "      ...n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))]) [{'pca__n_components': array([ 2,  9, 16, 23, 30, 37]), 'ranfor__n_estimators': [10, 50, 100], 'ranfor__class_weight': ['balanced', {1: 4, 0: 1}, {1: 2, 0: 1}]}]\n",
      "Start training...\n",
      "Model Description:\n",
      " Pipeline(memory=None,\n",
      "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=23, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('ranfor', RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_no...mators=100, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))])\n",
      ">>> best model results: sensitivity: 0.47\tspecificity: 0.870\tauc:0.8\n",
      "Raw data loaded with shape: (28454, 62)\n",
      "Data Normalized.\n",
      "Check the null values:\n",
      "Here are columns with NaN values:\n",
      "Check the loaded dataset: \n",
      " train with shape (21340, 39)\n",
      "test with shape: (7114, 39)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('ranfor', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "      ...n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))]) [{'pca__n_components': array([ 2,  9, 16, 23, 30, 37]), 'ranfor__n_estimators': [10, 50, 100], 'ranfor__class_weight': ['balanced', {1: 4, 0: 1}, {1: 2, 0: 1}]}]\n",
      "Start training...\n",
      "Model Description:\n",
      " Pipeline(memory=None,\n",
      "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=23, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('ranfor', RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_no...mators=100, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))])\n",
      ">>> best model results: sensitivity: 0.52\tspecificity: 0.880\tauc:0.83\n",
      "Raw data loaded with shape: (28454, 62)\n",
      "Data Normalized.\n",
      "Check the null values:\n",
      "Here are columns with NaN values:\n",
      "Check the loaded dataset: \n",
      " train with shape (21340, 39)\n",
      "test with shape: (7114, 39)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('ranfor', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "      ...n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))]) [{'pca__n_components': array([ 2,  9, 16, 23, 30, 37]), 'ranfor__n_estimators': [10, 50, 100], 'ranfor__class_weight': ['balanced', {1: 4, 0: 1}, {1: 2, 0: 1}]}]\n",
      "Start training...\n",
      "Model Description:\n",
      " Pipeline(memory=None,\n",
      "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=23, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('ranfor', RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_no...mators=100, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))])\n",
      ">>> best model results: sensitivity: 0.51\tspecificity: 0.890\tauc:0.83\n",
      "Raw data loaded with shape: (28454, 62)\n",
      "Data Normalized.\n",
      "Check the null values:\n",
      "Here are columns with NaN values:\n",
      "Check the loaded dataset: \n",
      " train with shape (21340, 39)\n",
      "test with shape: (7114, 39)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('ranfor', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "      ...n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))]) [{'pca__n_components': array([ 2,  9, 16, 23, 30, 37]), 'ranfor__n_estimators': [10, 50, 100], 'ranfor__class_weight': ['balanced', {1: 4, 0: 1}, {1: 2, 0: 1}]}]\n",
      "Start training...\n",
      "Model Description:\n",
      " Pipeline(memory=None,\n",
      "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=23, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('ranfor', RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_no...mators=100, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))])\n",
      ">>> best model results: sensitivity: 0.51\tspecificity: 0.880\tauc:0.82\n",
      "Sensitivity: 0.5025 0.019202864369671536 nan nan\n",
      "Specificity: 0.88 0.007071067811865481 nan nan\n",
      "AUC: 0.82 0.012247448713915856 nan nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shuang/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/shuang/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/shuang/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/numpy/core/_methods.py:135: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/home/shuang/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/numpy/core/_methods.py:105: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/home/shuang/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/numpy/core/_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data loaded with shape: (20000, 62)\n",
      "Data Normalized.\n",
      "Check the null values:\n",
      "Here are columns with NaN values:\n",
      "Check the loaded dataset: \n",
      " train with shape (15000, 39)\n",
      "test with shape: (5000, 39)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('ranfor', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "      ...n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))]) [{'pca__n_components': array([ 2,  9, 16, 23, 30, 37]), 'ranfor__n_estimators': [10, 50, 100], 'ranfor__class_weight': ['balanced', {1: 4, 0: 1}, {1: 2, 0: 1}]}]\n",
      "Start training...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-798555ea892a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0met_filepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgt_filepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_filepath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mexamineModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-c698ac275a6b>\u001b[0m in \u001b[0;36mexamineModel\u001b[0;34m(model_name, trainPath, testPath, label_name, savefilename, keep, exclude, display)\u001b[0m\n\u001b[1;32m     36\u001b[0m                                  \u001b[0mvalid_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                                  \u001b[0mreturnRes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                                  display=display)\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sensitivity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensitivity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'specificity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspecificity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/boxy_eqtm/tools/../lib/model/modelBuild.py\u001b[0m in \u001b[0;36mtrain_and_display_output\u001b[0;34m(self, train_data, valid_data, returnRes, display)\u001b[0m\n\u001b[1;32m     41\u001b[0m         self.classifier = GridSearchCV(estimator=self.pipeline,\n\u001b[1;32m     42\u001b[0m                                   param_grid=self.param_grid)\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0msensitivity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspecificity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefilename\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 328\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "PROJECT_DIR = '/home/shuang/projects/boxy_eqtm'\n",
    "data_folder = os.path.join(PROJECT_DIR,'data',\n",
    "                           'eqtmZscores','final')\n",
    "et_filepath = os.path.join(data_folder,'2017-12-09-eQTLsFDR-et0_withExpressionTssMethyOverlap.txt')\n",
    "gt_filepath = os.path.join(data_folder,'2017-12-09-eQTLsFDR-gt0_withExpressionTssMethyOverlap.txt')\n",
    "random_filepath = os.path.join(data_folder,'random20k_gt0.5_withTss_withExpressionTssMethyOverlap.txt')\n",
    "\n",
    "model_name = 'ranfor'\n",
    "trainPath = et_filepath\n",
    "testPath = et_filepath\n",
    "exclude = ['SNPName','SNPChr','PValue','SNPChrPos','ProbeName','ProbeChr','ProbeCenterChrPos', \n",
    "           'CisTrans', 'SNPType', 'AlleleAssessed','DatasetsWhereSNPProbePairIsAvailableAndPassesQC',\n",
    "           'DatasetsZScores', 'DatasetsNrSamples','IncludedDatasetsMeanProbeExpression',\n",
    "           'IncludedDatasetsProbeExpressionVariance', 'HGNCName',\n",
    "           'IncludedDatasetsCorrelationCoefficient', 'Meta-Beta (SE)', 'Beta (SE)',\n",
    "           'FoldChange', 'FDR','checkChr','SNPName_ProbeName']\n",
    "keep = ['OverallZScore']\n",
    "\n",
    "for filepath in [et_filepath,gt_filepath,random_filepath]:\n",
    "    examineModel(model_name,filepath,filepath,keep=keep,exclude=exclude,display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_class_filepath = os.path.join(eqtm_overlap_withTSSExpressionMethy,'multi_class.txt')\n",
    "multi_class = p.read_csv(multi_class_filepath)\n",
    "multi_class.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
